{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa67053-3f1c-4134-91d3-dbbaf0bc8280",
   "metadata": {},
   "source": [
    "## ESM-2: Single Protein Evolution ##\n",
    "\n",
    "ESM-2 is a state-of-the-art protein model trained on a masked language modelling objective. It is suitable for fine-tuning on a wide range of tasks that take protein sequences as input. For detailed information on the model architecture and training data, please refer to the accompanying paper. You may also be interested in some demo notebooks (PyTorch, TensorFlow) which demonstrate how to fine-tune ESM-2 models on your tasks of interest.\n",
    "\n",
    "Several ESM-2 checkpoints are available in the Hub with varying sizes. \n",
    "\n",
    "Larger sizes generally have somewhat better accuracy, but require much more memory and time to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f789d-2d6c-417d-b8da-8d8ecdf7a91c",
   "metadata": {},
   "source": [
    "The first method focuses on evolving a single protein sequence. The protein sequence is initially converted into a FASTA format, a widely used text-based format for representing nucleotide or peptide sequences. Each sequence is prefaced with a descriptive line starting with '>', followed by the sequence itself in subsequent lines.\n",
    "\n",
    "The ESM-2 model and its tokenizer are then loaded as the expert system for directed evolution. The model, pretrained on vast protein sequence data, understands the complex relationships between amino acids. The tokenizer converts the protein sequences into a format that the ESM-2 model can process.\n",
    "\n",
    "Directed evolution is initiated using the EvoProtGrad's DirectedEvolution class, specifying the ESM-2 model as the expert. The process involves running several parallel chains of Markov Chain Monte Carlo (MCMC) steps. Each chain explores the sequence space, proposing mutations at each step. The EvoProtGrad framework then evaluates these mutations based on the expert model's predictions, accepting mutations that are likely to improve the desired protein characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3242fd8-bb78-4407-a653-66f984b0df01",
   "metadata": {},
   "source": [
    "Resources\n",
    "\n",
    "Blog post: https://huggingface.co/blog/AmelieSchreiber/directed-evolution-with-esm2\n",
    "\n",
    "Model weights: https://huggingface.co/facebook/esm2_t30_150M_UR50D\n",
    "\n",
    "ESM GitHub repository: https://github.com/facebookresearch/esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6139512-2a52-4791-b19d-c96ccfc15a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project module version: 0.0.post1.dev23+gc9ac203\n",
      "PyTorch version:        2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import cuda\n",
    "\n",
    "# Huggingface imports\n",
    "import evo_prot_grad\n",
    "from transformers import AutoTokenizer, EsmForMaskedLM\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import esm\n",
    "from esm.evoprotgrad import EvoProtGrad\n",
    "from esm.evoprotgrad import torch_device\n",
    "print(f'Project module version: {esm.__version__}')\n",
    "print(f'PyTorch version:        {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533195b-34f1-4bb3-b555-5a14e20eb55e",
   "metadata": {},
   "source": [
    "### Set the GPU device ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bafe90-1548-4945-8880-8bd57e2cd99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device_id': 0,\n",
       " 'device': device(type='cuda', index=0),\n",
       " 'device_name': 'NVIDIA A100-SXM4-80GB',\n",
       " 'cudnn_version': 8906,\n",
       " 'torch_version': '2.1.2+cu121'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 20 09:29:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:DD:00.0 Off |                    0 |\n",
      "| N/A   26C    P0              63W / 500W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Where do we want to put the model weights.\n",
    "project_dir = os.path.normpath('/n/data1/hms/ccb/projects/esm')\n",
    "cache_dir = os.path.join(project_dir, 'model_weights')\n",
    "Path(cache_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Free up GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the device for the model\n",
    "device_dict = torch_device()\n",
    "display(device_dict)\n",
    "torch.set_float32_matmul_precision(precision='high')\n",
    "!nvidia-smi\n",
    "\n",
    "# Now, get the device name\n",
    "device = device_dict.get('device')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ddd381-6830-44c7-9493-8171a96e2c8b",
   "metadata": {},
   "source": [
    "### Create the expert model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13368f14-7310-4739-8ef3-d0c031ad44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and weights for t30_150M model. This can take a while.\n",
      "Mon May 20 09:29:02 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:DD:00.0 Off |                    0 |\n",
      "| N/A   26C    P0              71W / 500W |   1125MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     30478      C   ...s/ccb/projects/esm/.venv/bin/python     1112MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/facebook/esm2_t33_650M_UR50D\n",
    "esm_checkpoints = {\n",
    "    't48_15B': 'facebook/esm2_t48_15B_UR50D',\n",
    "    't36_3B': 'facebook/esm2_t36_3B_UR50D',\n",
    "    't33_650M': 'facebook/esm2_t33_650M_UR50D',\n",
    "    't30_150M': 'facebook/esm2_t30_150M_UR50D',\n",
    "    't12_35M': 'facebook/esm2_t12_35M_UR50D',\n",
    "    't6/8M': 'facebook/esm2_t6_8M_UR50D',\n",
    "    'default': 'facebook/esm2_t30_150M_UR50D'\n",
    "}\n",
    "\n",
    "def set_expert(name='esm', checkpoint='default', device=None, cache_dir=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        name: (str) The name of the expert. Default is 'esm'.\n",
    "        checkpoint: (str) The name of the checkpoint. Default is 'default'.\n",
    "        device: (str) The device to run the expert on. Default is None.\n",
    "        **kwargs: Additional keyword arguments for the method.\n",
    "    Returns:\n",
    "        expert: The expert object that has been set.\n",
    "    \"\"\"\n",
    "    checkpoint = esm_checkpoints.get(checkpoint)\n",
    "    expert = evo_prot_grad.get_expert(\n",
    "        expert_name=name,\n",
    "        model=EsmForMaskedLM.from_pretrained(checkpoint, cache_dir=cache_dir),\n",
    "        tokenizer=AutoTokenizer.from_pretrained(checkpoint, cache_dir=cache_dir),\n",
    "        temperature=0.95,\n",
    "        device=device)\n",
    "    return expert\n",
    "\n",
    "# On the A100 GPU, we can load the big model. The weights may need to be downloaded which can take a while.\n",
    "checkpoint = 't30_150M'\n",
    "print(f'Loading model and weights for {checkpoint} model. This can take a while.')\n",
    "expert = set_expert(checkpoint=checkpoint, device=device, cache_dir=cache_dir)\n",
    "\n",
    "# Save some expert parameters\n",
    "model_dict = {'model': expert.model,\n",
    "              'device': expert.device,\n",
    "              'temperature': expert.temperature,\n",
    "              'vocabulary': expert.alphabet,\n",
    "              'tokenizer': expert.tokenizer}\n",
    "\n",
    "# Let's see how mubh GPU memory we are using\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fff750a-bf1a-4145-a5d5-681cb1ad3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evo_prot_grad(raw_protein_sequence, expert):\n",
    "    # Convert raw protein sequence to the format expected by EvoProtGrad\n",
    "    # Usually, protein sequences are handled in FASTA format, so we create a mock FASTA string\n",
    "    fasta_format_sequence = f\">Input_Sequence\\n{raw_protein_sequence}\"\n",
    "\n",
    "    # Save the mock FASTA string to a temporary file\n",
    "    temp_fasta_path = \"temp_input_sequence.fasta\"\n",
    "    with open(temp_fasta_path, \"w\") as file:\n",
    "        file.write(fasta_format_sequence)\n",
    "\n",
    "    # Initialize Directed Evolution with the ESM-2 expert\n",
    "    directed_evolution = evo_prot_grad.DirectedEvolution(\n",
    "        wt_fasta=temp_fasta_path,    # path to the temporary FASTA file\n",
    "        output='all',                # can be 'best', 'last', or 'all' variants\n",
    "        experts=[expert],            # list of experts, in this case only ESM-2\n",
    "        parallel_chains=1,           # number of parallel chains to run\n",
    "        n_steps=20,                  # number of MCMC steps per chain\n",
    "        max_mutations=10,            # maximum number of mutations per variant\n",
    "        verbose=True                 # print debug info\n",
    "    )\n",
    "\n",
    "    # Run the evolution process\n",
    "    variants, scores = directed_evolution()\n",
    "\n",
    "    return variants, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2955c2-d61d-4eb4-95c7-f9b3429aec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Wildtype sequence: M A L W M R L L P L L A L L A L W G P D P A A A F V N Q H L C G S H L V E A L Y L V C G E R G F F Y T P K T R R E A E D L Q V G Q V E L G G G P G A G S L Q P L A L E G S L Q K R G I V E Q C C T S I C S L Y Q L E N Y C N\n",
      "step 0 acceptance rate: 6.6221\n",
      ">chain 0, Product of Experts score: -0.6628\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[0mI\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 1 acceptance rate: 9.1179\n",
      ">chain 0, Product of Experts score: -0.5026\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mP\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[0mI\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 2 acceptance rate: 1.0000\n",
      ">chain 0, Product of Experts score: -0.5026\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mP\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[0mI\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 3 acceptance rate: 2.0999\n",
      ">chain 0, Product of Experts score: -0.4516\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[91mR\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mP\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[0mI\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 4 acceptance rate: 72.8830\n",
      ">chain 0, Product of Experts score: -0.1778\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[91mG\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[91mQ\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[91mE\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[91mR\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mP\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[0mI\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 5 acceptance rate: 9.2932\n",
      ">chain 0, Product of Experts score: -0.2925\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[91mG\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[91mQ\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[91mE\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[91mR\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mP\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[91mH\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[0mI\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 6 acceptance rate: 12.1640\n",
      ">chain 0, Product of Experts score: 1.6621\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[91mG\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[91mQ\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[91mE\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[91mR\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mP\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[91mH\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 7 acceptance rate: 11.0866\n",
      ">chain 0, Product of Experts score: 1.8382\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[91mG\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[91mQ\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[91mE\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[91mR\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mP\u001b[0m \u001b[0mV\u001b[0m \u001b[91mN\u001b[0m \u001b[0mL\u001b[0m \u001b[91mH\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[91mF\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 8 acceptance rate: 0.3372\n",
      ">chain 0, Product of Experts score: 2.2547\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n",
      "step 9 acceptance rate: 4.8069\n",
      ">chain 0, Product of Experts score: 1.6246\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mM\u001b[0m\n",
      "step 10 acceptance rate: 0.7727\n",
      ">chain 0, Product of Experts score: 1.6246\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mM\u001b[0m\n",
      "step 11 acceptance rate: 1.0000\n",
      ">chain 0, Product of Experts score: 1.3569\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mM\u001b[0m\n",
      "step 12 acceptance rate: 19.9854\n",
      ">chain 0, Product of Experts score: 2.4798\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mK\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mM\u001b[0m\n",
      "step 13 acceptance rate: 1.0000\n",
      ">chain 0, Product of Experts score: 2.4798\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mK\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mM\u001b[0m\n",
      "step 14 acceptance rate: 5.6612\n",
      ">chain 0, Product of Experts score: 1.9225\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[91mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mK\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mM\u001b[0m\n",
      "step 15 acceptance rate: 5.0314\n",
      ">chain 0, Product of Experts score: 1.9551\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[91mG\u001b[0m \u001b[91mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[91mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mK\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mM\u001b[0m\n",
      "step 16 acceptance rate: 1.3641\n",
      ">chain 0, Product of Experts score: 2.7974\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[91mG\u001b[0m \u001b[91mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[91mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mK\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mE\u001b[0m\n",
      "step 17 acceptance rate: 0.0412\n",
      ">chain 0, Product of Experts score: 2.7974\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[91mG\u001b[0m \u001b[91mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[91mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mK\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mE\u001b[0m\n",
      "step 18 acceptance rate: 2.5609\n",
      ">chain 0, Product of Experts score: 2.2571\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mD\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[91mG\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[91mA\u001b[0m \u001b[91mG\u001b[0m \u001b[91mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mG\u001b[0m \u001b[91mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[91mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[91mA\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[91mK\u001b[0m \u001b[91mT\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[91mE\u001b[0m\n",
      "step 19 acceptance rate: 1.8356\n",
      ">chain 0, Product of Experts score: -1.1364\n",
      "\u001b[0mM\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mM\u001b[0m \u001b[0mR\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mW\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[91mI\u001b[0m \u001b[0mP\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mA\u001b[0m \u001b[0mF\u001b[0m \u001b[0mV\u001b[0m \u001b[0mN\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mH\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mL\u001b[0m \u001b[0mV\u001b[0m \u001b[0mC\u001b[0m \u001b[0mG\u001b[0m \u001b[0mE\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mF\u001b[0m \u001b[0mF\u001b[0m \u001b[0mY\u001b[0m \u001b[0mT\u001b[0m \u001b[0mP\u001b[0m \u001b[0mK\u001b[0m \u001b[0mT\u001b[0m \u001b[0mR\u001b[0m \u001b[0mR\u001b[0m \u001b[0mE\u001b[0m \u001b[0mA\u001b[0m \u001b[0mE\u001b[0m \u001b[0mD\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mG\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mL\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mG\u001b[0m \u001b[0mP\u001b[0m \u001b[0mG\u001b[0m \u001b[0mA\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mP\u001b[0m \u001b[0mL\u001b[0m \u001b[0mA\u001b[0m \u001b[0mL\u001b[0m \u001b[91mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mK\u001b[0m \u001b[0mR\u001b[0m \u001b[0mG\u001b[0m \u001b[0mI\u001b[0m \u001b[0mV\u001b[0m \u001b[0mE\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mC\u001b[0m \u001b[0mC\u001b[0m \u001b[0mT\u001b[0m \u001b[0mS\u001b[0m \u001b[0mI\u001b[0m \u001b[0mC\u001b[0m \u001b[0mS\u001b[0m \u001b[0mL\u001b[0m \u001b[0mY\u001b[0m \u001b[0mQ\u001b[0m \u001b[0mL\u001b[0m \u001b[0mE\u001b[0m \u001b[0mN\u001b[0m \u001b[0mY\u001b[0m \u001b[0mC\u001b[0m \u001b[0mN\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "raw_protein_sequence = \"MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGERGFFYTPKTRREAEDLQVGQVELGGGPGAGSLQPLALEGSLQKRGIVEQCCTSICSLYQLENYCN\"  # Replace with your protein sequence\n",
    "variants, scores = run_evo_prot_grad(raw_protein_sequence, expert=expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54146200-f81b-4389-aefc-4cefedaaf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the results\n",
    "#for variant, score in zip(variants, scores):\n",
    "#    print(f\"Variant: {variant}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b4e3cb-968e-487e-9448-20ff0b198ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>score</th>\n",
       "      <th>pos</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>3.384270</td>\n",
       "      <td>[4, 5, 16, 25, 26, 68, 73, 75, 93, 102]</td>\n",
       "      <td>[M, R, W, V, N, G, A, S, Q, Y]</td>\n",
       "      <td>[A, A, T, T, V, A, H, W, D, A]</td>\n",
       "      <td>MALWAALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>3.384270</td>\n",
       "      <td>[102]</td>\n",
       "      <td>[Y]</td>\n",
       "      <td>[P]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2.354532</td>\n",
       "      <td>[4, 5, 16, 25, 26, 68, 75, 93, 102]</td>\n",
       "      <td>[M, R, W, V, N, G, S, Q, Y]</td>\n",
       "      <td>[P, A, T, T, V, A, W, D, A]</td>\n",
       "      <td>MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2.354532</td>\n",
       "      <td>[4, 5, 16, 25, 26, 68, 75, 93, 102]</td>\n",
       "      <td>[M, R, W, V, N, G, S, Q, Y]</td>\n",
       "      <td>[P, A, T, T, V, A, W, D, A]</td>\n",
       "      <td>MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2.354532</td>\n",
       "      <td>[4, 5, 16, 25, 26, 68, 75, 93, 102]</td>\n",
       "      <td>[M, R, W, V, N, G, S, Q, Y]</td>\n",
       "      <td>[P, A, T, T, V, A, W, D, A]</td>\n",
       "      <td>MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>2.354532</td>\n",
       "      <td>[4, 5, 16, 25, 26, 68, 75, 93, 102]</td>\n",
       "      <td>[M, R, W, V, N, G, S, Q, Y]</td>\n",
       "      <td>[P, A, T, T, V, A, W, D, A]</td>\n",
       "      <td>MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>2.354532</td>\n",
       "      <td>[4, 5, 16, 25, 26, 68, 75, 93, 102]</td>\n",
       "      <td>[M, R, W, V, N, G, S, Q, Y]</td>\n",
       "      <td>[P, A, T, T, V, A, W, D, A]</td>\n",
       "      <td>MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.354532</td>\n",
       "      <td>[4, 5, 16, 25, 26, 68, 75, 93, 102]</td>\n",
       "      <td>[M, R, W, V, N, G, S, Q, Y]</td>\n",
       "      <td>[P, A, T, T, V, A, W, D, A]</td>\n",
       "      <td>MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>1.016670</td>\n",
       "      <td>[25, 26, 56, 63, 72, 83, 98, 102]</td>\n",
       "      <td>[V, N, E, G, G, G, I, Y]</td>\n",
       "      <td>[A, E, L, H, P, P, A, P]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFAEQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>1.016670</td>\n",
       "      <td>[25, 26, 56, 63, 72, 83, 98, 102]</td>\n",
       "      <td>[V, N, E, G, G, G, I, Y]</td>\n",
       "      <td>[A, E, L, H, P, P, A, P]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFAEQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>0.786117</td>\n",
       "      <td>[102]</td>\n",
       "      <td>[Y]</td>\n",
       "      <td>[P]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>0.377878</td>\n",
       "      <td>[72, 102]</td>\n",
       "      <td>[G, Y]</td>\n",
       "      <td>[P, P]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.202985</td>\n",
       "      <td>[4, 5, 16, 26, 93, 102]</td>\n",
       "      <td>[M, R, W, N, Q, Y]</td>\n",
       "      <td>[P, A, T, V, D, A]</td>\n",
       "      <td>MALWPALLPLLALLALTGPDPAAAFVVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.381009</td>\n",
       "      <td>[56, 72, 102]</td>\n",
       "      <td>[E, G, Y]</td>\n",
       "      <td>[L, P, P]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.897206</td>\n",
       "      <td>[25, 56, 63, 72, 102]</td>\n",
       "      <td>[V, E, G, G, Y]</td>\n",
       "      <td>[A, L, H, P, P]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFANQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.245476</td>\n",
       "      <td>[26, 102]</td>\n",
       "      <td>[N, Y]</td>\n",
       "      <td>[V, A]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.245476</td>\n",
       "      <td>[26, 102]</td>\n",
       "      <td>[N, Y]</td>\n",
       "      <td>[V, A]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.552455</td>\n",
       "      <td>[5, 16, 26, 93, 102]</td>\n",
       "      <td>[R, W, N, Q, Y]</td>\n",
       "      <td>[A, T, V, D, A]</td>\n",
       "      <td>MALWMALLPLLALLALTGPDPAAAFVVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.870689</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[N]</td>\n",
       "      <td>[V]</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.287148</td>\n",
       "      <td>[5, 26, 102]</td>\n",
       "      <td>[R, N, Y]</td>\n",
       "      <td>[A, V, A]</td>\n",
       "      <td>MALWMALLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variant     score                                      pos  \\\n",
       "0        12  3.384270  [4, 5, 16, 25, 26, 68, 73, 75, 93, 102]   \n",
       "1        13  3.384270                                    [102]   \n",
       "2         6  2.354532      [4, 5, 16, 25, 26, 68, 75, 93, 102]   \n",
       "3         7  2.354532      [4, 5, 16, 25, 26, 68, 75, 93, 102]   \n",
       "4        10  2.354532      [4, 5, 16, 25, 26, 68, 75, 93, 102]   \n",
       "5        11  2.354532      [4, 5, 16, 25, 26, 68, 75, 93, 102]   \n",
       "6         9  2.354532      [4, 5, 16, 25, 26, 68, 75, 93, 102]   \n",
       "7         8  2.354532      [4, 5, 16, 25, 26, 68, 75, 93, 102]   \n",
       "8        18  1.016670        [25, 26, 56, 63, 72, 83, 98, 102]   \n",
       "9        19  1.016670        [25, 26, 56, 63, 72, 83, 98, 102]   \n",
       "10       14  0.786117                                    [102]   \n",
       "11       15  0.377878                                [72, 102]   \n",
       "12        5  0.202985                  [4, 5, 16, 26, 93, 102]   \n",
       "13       16 -0.381009                            [56, 72, 102]   \n",
       "14       17 -0.897206                    [25, 56, 63, 72, 102]   \n",
       "15        1 -1.245476                                [26, 102]   \n",
       "16        2 -1.245476                                [26, 102]   \n",
       "17        4 -1.552455                     [5, 16, 26, 93, 102]   \n",
       "18        0 -1.870689                                     [26]   \n",
       "19        3 -2.287148                             [5, 26, 102]   \n",
       "\n",
       "                            source                          target  \\\n",
       "0   [M, R, W, V, N, G, A, S, Q, Y]  [A, A, T, T, V, A, H, W, D, A]   \n",
       "1                              [Y]                             [P]   \n",
       "2      [M, R, W, V, N, G, S, Q, Y]     [P, A, T, T, V, A, W, D, A]   \n",
       "3      [M, R, W, V, N, G, S, Q, Y]     [P, A, T, T, V, A, W, D, A]   \n",
       "4      [M, R, W, V, N, G, S, Q, Y]     [P, A, T, T, V, A, W, D, A]   \n",
       "5      [M, R, W, V, N, G, S, Q, Y]     [P, A, T, T, V, A, W, D, A]   \n",
       "6      [M, R, W, V, N, G, S, Q, Y]     [P, A, T, T, V, A, W, D, A]   \n",
       "7      [M, R, W, V, N, G, S, Q, Y]     [P, A, T, T, V, A, W, D, A]   \n",
       "8         [V, N, E, G, G, G, I, Y]        [A, E, L, H, P, P, A, P]   \n",
       "9         [V, N, E, G, G, G, I, Y]        [A, E, L, H, P, P, A, P]   \n",
       "10                             [Y]                             [P]   \n",
       "11                          [G, Y]                          [P, P]   \n",
       "12              [M, R, W, N, Q, Y]              [P, A, T, V, D, A]   \n",
       "13                       [E, G, Y]                       [L, P, P]   \n",
       "14                 [V, E, G, G, Y]                 [A, L, H, P, P]   \n",
       "15                          [N, Y]                          [V, A]   \n",
       "16                          [N, Y]                          [V, A]   \n",
       "17                 [R, W, N, Q, Y]                 [A, T, V, D, A]   \n",
       "18                             [N]                             [V]   \n",
       "19                       [R, N, Y]                       [A, V, A]   \n",
       "\n",
       "                                             sequence  \n",
       "0   MALWAALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...  \n",
       "1   MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...  \n",
       "2   MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...  \n",
       "3   MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...  \n",
       "4   MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...  \n",
       "5   MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...  \n",
       "6   MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...  \n",
       "7   MALWPALLPLLALLALTGPDPAAAFTVQHLCGSHLVEALYLVCGER...  \n",
       "8   MALWMRLLPLLALLALWGPDPAAAFAEQHLCGSHLVEALYLVCGER...  \n",
       "9   MALWMRLLPLLALLALWGPDPAAAFAEQHLCGSHLVEALYLVCGER...  \n",
       "10  MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...  \n",
       "11  MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...  \n",
       "12  MALWPALLPLLALLALTGPDPAAAFVVQHLCGSHLVEALYLVCGER...  \n",
       "13  MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...  \n",
       "14  MALWMRLLPLLALLALWGPDPAAAFANQHLCGSHLVEALYLVCGER...  \n",
       "15  MALWMRLLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...  \n",
       "16  MALWMRLLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...  \n",
       "17  MALWMALLPLLALLALTGPDPAAAFVVQHLCGSHLVEALYLVCGER...  \n",
       "18  MALWMRLLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...  \n",
       "19  MALWMALLPLLALLALWGPDPAAAFVVQHLCGSHLVEALYLVCGER...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run class method. This puts the results into a nice table, sorte by score\n",
    "epg = EvoProtGrad(expert=expert, cache_dir=cache_dir)\n",
    "output_dir = os.path.join(os.environ['HOME'], 'data', 'protein_evolution')\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "var_df = epg.single_evolute(raw_protein_sequence=raw_protein_sequence, output_dir=output_dir)\n",
    "display(var_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
