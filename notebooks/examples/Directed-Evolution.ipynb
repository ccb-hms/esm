{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa67053-3f1c-4134-91d3-dbbaf0bc8280",
   "metadata": {},
   "source": [
    "## ESM-2 ##\n",
    "\n",
    "ESM-2 is a state-of-the-art protein model trained on a masked language modelling objective. It is suitable for fine-tuning on a wide range of tasks that take protein sequences as input. For detailed information on the model architecture and training data, please refer to the accompanying paper. You may also be interested in some demo notebooks (PyTorch, TensorFlow) which demonstrate how to fine-tune ESM-2 models on your tasks of interest.\n",
    "\n",
    "Several ESM-2 checkpoints are available in the Hub with varying sizes. \n",
    "\n",
    "Larger sizes generally have somewhat better accuracy, but require much more memory and time to train.\n",
    "\n",
    "Model weights are available here:\n",
    "\n",
    "https://huggingface.co/facebook/esm2_t30_150M_UR50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6139512-2a52-4791-b19d-c96ccfc15a4a",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Huggingface imports\n",
    "import evo_prot_grad\n",
    "from transformers import AutoTokenizer, EsmForMaskedLM\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(linewidth=110)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import esm\n",
    "from esm.evoprotgrad import EvoProtGrad\n",
    "from esm.evoprotgrad import torch_device\n",
    "print(f'Project module version: {esm.__version__}')\n",
    "print(f'PyTorch version:        {torch.__version__}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "55eb63b0-b1ff-4ea3-b840-8c172f6923f8",
   "metadata": {},
   "source": [
    "### Single Protein Evolution ###\n",
    "\n",
    "The first method focuses on evolving a single protein sequence. The protein sequence is initially converted into a FASTA format, a widely used text-based format for representing nucleotide or peptide sequences. Each sequence is prefaced with a descriptive line starting with '>', followed by the sequence itself in subsequent lines.\n",
    "\n",
    "The ESM-2 model and its tokenizer are then loaded as the expert system for directed evolution. The model, pretrained on vast protein sequence data, understands the complex relationships between amino acids. The tokenizer converts the protein sequences into a format that the ESM-2 model can process.\n",
    "\n",
    "Directed evolution is initiated using the EvoProtGrad's DirectedEvolution class, specifying the ESM-2 model as the expert. The process involves running several parallel chains of Markov Chain Monte Carlo (MCMC) steps. Each chain explores the sequence space, proposing mutations at each step. The EvoProtGrad framework then evaluates these mutations based on the expert model's predictions, accepting mutations that are likely to improve the desired protein characteristics.\n",
    "\n",
    "https://huggingface.co/blog/AmelieSchreiber/directed-evolution-with-esm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fff750a-bf1a-4145-a5d5-681cb1ad3fc7",
   "metadata": {},
   "source": [
    "def run_evo_prot_grad(raw_protein_sequence):\n",
    "    # Convert raw protein sequence to the format expected by EvoProtGrad\n",
    "    # Usually, protein sequences are handled in FASTA format, so we create a mock FASTA string\n",
    "    fasta_format_sequence = f\">Input_Sequence\\n{raw_protein_sequence}\"\n",
    "\n",
    "    # Save the mock FASTA string to a temporary file\n",
    "    temp_fasta_path = \"temp_input_sequence.fasta\"\n",
    "    with open(temp_fasta_path, \"w\") as file:\n",
    "        file.write(fasta_format_sequence)\n",
    "\n",
    "    # Load the ESM-2 model and tokenizer as the expert\n",
    "    esm2_expert = evo_prot_grad.get_expert(\n",
    "        'esm',\n",
    "        model=EsmForMaskedLM.from_pretrained(\"facebook/esm2_t30_150M_UR50D\"),\n",
    "        tokenizer=AutoTokenizer.from_pretrained(\"facebook/esm2_t30_150M_UR50D\"),\n",
    "        temperature=0.95,\n",
    "        device='cuda'  # or 'cpu' if GPU is not available\n",
    "    )\n",
    "\n",
    "    # Initialize Directed Evolution with the ESM-2 expert\n",
    "    directed_evolution = evo_prot_grad.DirectedEvolution(\n",
    "        wt_fasta=temp_fasta_path,    # path to the temporary FASTA file\n",
    "        output='all',               # can be 'best', 'last', or 'all' variants\n",
    "        experts=[esm2_expert],       # list of experts, in this case only ESM-2\n",
    "        parallel_chains=1,           # number of parallel chains to run\n",
    "        n_steps=20,                  # number of MCMC steps per chain\n",
    "        max_mutations=10,            # maximum number of mutations per variant\n",
    "        verbose=True                # print debug info\n",
    "    )\n",
    "\n",
    "    # Run the evolution process\n",
    "    variants, scores = directed_evolution()\n",
    "\n",
    "    # Process the results\n",
    "    #for variant, score in zip(variants, scores):\n",
    "    #    print(f\"Variant: {variant}, Score: {score}\")\n",
    "\n",
    "    return variants, scores"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2409d648-3f1c-4917-b7b6-72fa28841cd3",
   "metadata": {},
   "source": [
    "# Get the device for the model\n",
    "device_dict = torch_device()\n",
    "display(device_dict)\n",
    "torch.set_float32_matmul_precision(precision='high')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2955c2-d61d-4eb4-95c7-f9b3429aec90",
   "metadata": {},
   "source": [
    "raw_protein_sequence = \"MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGERGFFYTPKTRREAEDLQVGQVELGGGPGAGSLQPLALEGSLQKRGIVEQCCTSICSLYQLENYCN\"  # Replace with your protein sequence\n",
    "variants, scores = run_evo_prot_grad(raw_protein_sequence)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b4e3cb-968e-487e-9448-20ff0b198ba9",
   "metadata": {},
   "source": [
    "# Run class method\n",
    "epg = EvoProtGrad()\n",
    "output_dir = os.path.join(os.environ['HOME'], 'data', 'protein_evolution')\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "var_df = epg.single_evolute(raw_protein_sequence=raw_protein_sequence, output_dir=output_dir)\n",
    "display(var_df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bb294733-f56b-4573-a81c-bd46ba77293e",
   "metadata": {},
   "source": [
    "### Paired Protein Evolution ###\n",
    "\n",
    "The second method extends this approach to paired protein sequences, separated by a specific marker â€“ in this case, a string of 20 'G' amino acids. This unique separator or linker allows for the simultaneous evolution of two protein sequences while preserving their individual integrity and the relational context.\n",
    "\n",
    "Similar to the single protein evolution, the paired sequences are formatted into a FASTA-like structure, replacing the ':' separator with the 'G' amino acid string. This modified sequence is then subjected to the directed evolution process, with the 'G' string region preserved to maintain the distinction between the two protein sequences.\n",
    "\n",
    "During the evolution process, mutations are proposed and evaluated across both protein sequences, considering their combined context. The preserved region ensures that mutations do not disrupt the separator, maintaining the integrity of the paired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a173a8c-0ca9-426e-bd18-450a50c6068e",
   "metadata": {},
   "source": [
    "def run_evo_prot_grad_on_paired_sequence(paired_protein_sequence):\n",
    "    # Replace ':' with a string of 20 'G' amino acids\n",
    "    separator = 'G' * 20\n",
    "    sequence_with_separator = paired_protein_sequence.replace(':', separator)\n",
    "\n",
    "    # Determine the start and end indices of the separator\n",
    "    separator_start_index = sequence_with_separator.find(separator)\n",
    "    separator_end_index = separator_start_index + len(separator)\n",
    "\n",
    "    # Format the sequence into FASTA format\n",
    "    fasta_format_sequence = f\">Paired_Protein_Sequence\\n{sequence_with_separator}\"\n",
    "\n",
    "    # Save the sequence to a temporary file\n",
    "    temp_fasta_path = \"temp_paired_sequence.fasta\"\n",
    "    with open(temp_fasta_path, \"w\") as file:\n",
    "        file.write(fasta_format_sequence)\n",
    "\n",
    "    # Load the ESM-2 model and tokenizer as the expert\n",
    "    esm2_expert = evo_prot_grad.get_expert(\n",
    "        'esm',\n",
    "        model=EsmForMaskedLM.from_pretrained(\"facebook/esm2_t30_150M_UR50D\"),\n",
    "        tokenizer=AutoTokenizer.from_pretrained(\"facebook/esm2_t30_150M_UR50D\"),\n",
    "        temperature=0.95,\n",
    "        device='cuda'  # or 'cpu' if GPU is not available\n",
    "    )\n",
    "\n",
    "    # Initialize Directed Evolution with the preserved separator region\n",
    "    directed_evolution = evo_prot_grad.DirectedEvolution(\n",
    "        wt_fasta=temp_fasta_path,\n",
    "        output='all',\n",
    "        experts=[esm2_expert],\n",
    "        parallel_chains=1,\n",
    "        n_steps=20,\n",
    "        max_mutations=10,\n",
    "        verbose=True,\n",
    "        preserved_regions=[(separator_start_index, separator_end_index)]  # Preserve the 'G' amino acids string\n",
    "    )\n",
    "\n",
    "    # Run the evolution process\n",
    "    variants, scores = directed_evolution()\n",
    "\n",
    "    # Process the results, replacing the 'G' amino acids string back to ':'\n",
    "    #for variant, score in zip(variants, scores):\n",
    "    #   evolved_sequence = variant.replace(separator, ':')\n",
    "    #    print(f\"Evolved Paired Sequence: {evolved_sequence}, Score: {score}\")\n",
    "\n",
    "    return variants, scores"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9242f6b-63b4-4398-bcdb-9174b6d0fb5e",
   "metadata": {},
   "source": [
    "paired_protein_sequence = \"MLTEVMEVWHGLVIAVVSLFLQACFLTAINYLLSRHMAHKSEQILKAASLQVPRPSPGHHHPPAVKEMKETQTERDIPMSDSLYRHDSDTPSDSLDSSCSSPPACQATEDVDYTQVVFSDPGELKNDSPLDYENIKEITDYVNVNPERHKPSFWYFVNPALSEPAEYDQVAM:MASPGSGFWSFGSEDGSGDSENPGTARAWCQVAQKFTGGIGNKLCALLYGDAEKPAESGGSQPPRAAARKAACACDQKPCSCSKVDVNYAFLHATDLLPACDGERPTLAFLQDVMNILLQYVVKSFDRSTKVIDFHYPNELLQEYNWELADQPQNLEEILMHCQTTLKYAIKTGHPRYFNQLSTGLDMVGLAADWLTSTANTNMFTYEIAPVFVLLEYVTLKKMREIIGWPGGSGDGIFSPGGAISNMYAMMIARFKMFPEVKEKGMAALPRLIAFTSEHSHFSLKKGAAALGIGTDSVILIKCDERGKMIPSDLERRILEAKQKGFVPFLVSATAGTTVYGAFDPLLAVADICKKYKIWMHVDAAWGGGLLMSRKHKWKLSGVERANSVTWNPHKMMGVPLQCSALLVREEGLMQNCNQMHASYLFQQDKHYDLSYDTGDKALQCGRHVDVFKLWLMWRAKGTTGFEAHVDKCLELAEYLYNIIKNREGYEMVFDGKPQHTNVCFWYIPPSLRTLEDNEERMSRLSKVAPVIKARMMEYGTTMVSYQPLGDKVNFFRMVISNPAATHQDIDFLIEEIERLGQDL\"  # Replace with your paired protein sequences\n",
    "variants, scores = run_evo_prot_grad_on_paired_sequence(paired_protein_sequence)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee3bcd8-3e86-4571-9c80-4a9f2f9bd05f",
   "metadata": {},
   "source": [
    "print(len(variants))\n",
    "print(len(scores))\n",
    "print(variants[0])"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
